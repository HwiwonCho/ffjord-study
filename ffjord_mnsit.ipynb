{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a54c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torchdiffeq import  odeint\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Batch_Size = 32\n",
    "data_dir = './data'\n",
    "os.makedirs(data_dir, exist_ok=True) # ë°ì´í„° í´ë” ìƒì„±\n",
    "\n",
    "INPUT_DIM = 28 * 28 \n",
    "TIME_T = 1.0\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. FFJORD ìµœì í™” ì „ì²˜ë¦¬ ì •ì˜ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)\n",
    "# ----------------------------------------------------------------------\n",
    "# MNIST ë°ì´í„°ì˜ í‰ê· (Mean)ê³¼ í‘œì¤€í¸ì°¨(Std)ëŠ” 0.5ë¥¼ ì‚¬ìš©í•˜ì—¬ [-1, 1] ë²”ìœ„ë¡œ í‘œì¤€í™”í•©ë‹ˆë‹¤.\n",
    "class AddNoise(object):\n",
    "    def __call__(self, tensor):\n",
    "        # 0 ~ 1/256 ì‚¬ì´ì˜ ê· ë“± ë¶„í¬ ë…¸ì´ì¦ˆ ì¶”ê°€ ì¸ë±ìŠ¤ëŠ” ì—°ì†ì ì´ì—¬ì•¼ í•œë‹¤\n",
    "        return tensor + torch.rand_like(tensor) / 256.0\n",
    "def logit_transform(x, alpha=1e-6):\n",
    "    x = x.clamp(min=alpha, max=1-alpha)\n",
    "    return torch.log(x / (1 - x))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    AddNoise(),       # [0, 1] ë²”ìœ„ë¡œ ë³€í™˜\n",
    "    transforms.Lambda(lambda x: logit_transform(x))\n",
    "])\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. ë°ì´í„° ë¡œë” ì •ì˜ (ìˆ˜ì •ëœ transform ì ìš©)\n",
    "# ----------------------------------------------------------------------\n",
    "train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca06223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì…ë ¥ìœ¼ë¡œ f(x,t)ì™€ y, të¥¼ ë°›ì•„ í—ˆí‚¨ìŠ¨ ì¶”ì •ëŸ‰ì„ ê³„ì‚°í•´ì£¼ëŠ” í•¨ìˆ˜\n",
    "#ì—¬ëŸ¬ë²ˆ ë°˜ë³µí•˜ì—¬ í‰ê· ì„ ë‚´ì–´ ì •í™•ë„ë¥¼ ë†’ì„\n",
    "def Huchinson_estimator(forwardzt, y,  num_epsilons):\n",
    "    Batch_Size=y.shape[0]\n",
    "    grad_avg=torch.zeros(y.shape[0],1).to(device).to(y.dtype)\n",
    "    for i in range(num_epsilons):\n",
    "        epsilon=torch.randn_like(y).to(device).to(y.dtype)\n",
    "        grad = torch.autograd.grad(forwardzt, y, grad_outputs=epsilon, create_graph=True)[0]\n",
    "        trace_estimate = torch.sum(grad*epsilon, dim=1, keepdim=True)\n",
    "        grad_avg += trace_estimate\n",
    "    grad_avg /= num_epsilons\n",
    "    return grad_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67a4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tê¹Œì§€ ode solve í•´ì£¼ê³  z(t)ì™€ trace ë°˜í™˜. Huchinson_estimator ì‚¬ìš©\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(dim+1, 128),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.Softplus(),\n",
    "            nn.Linear(128, dim),\n",
    "        ) \n",
    "        self.dims = dim\n",
    "\n",
    "    def forward1(self, t, x):\n",
    "        # t: scalar tensor on GPU\n",
    "        # x: (B, dim)\n",
    "        t_tensor = t.expand(x.shape[0], 1)  # repeat for batch\n",
    "        xt = torch.cat([x, t_tensor], dim=1)\n",
    "        return self.net(xt)\n",
    "    def forward(self, t, x):\n",
    "        z, logpz_T = x\n",
    "\n",
    "        # force t to GPU\n",
    "        if not torch.is_tensor(t):\n",
    "            t = torch.tensor([t], device=z.device, dtype=z.dtype)\n",
    "        else:\n",
    "            t = t.to(z.device).to(z.dtype)\n",
    "\n",
    "        z_flat = z.view(z.size(0), -1)\n",
    "\n",
    "        forwardzt = self.forward1(t, z_flat)\n",
    "        trace = Huchinson_estimator(forwardzt, z_flat, num_epsilons=2)\n",
    "\n",
    "        return forwardzt, -trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eebd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì „ì²´ ì‹ ê²½ë§\n",
    "class CNF(nn.Module):\n",
    "    def __init__(self, ode_func, T=0.5):\n",
    "        super().__init__()\n",
    "        self.ode_func = ode_func\n",
    "        self.time_t = T\n",
    "        self.rtol=1e-5\n",
    "        self.atol=1e-5\n",
    "    #ìˆœë°©í–¥ ì ë¶„ ìƒì„±ê³¼ì •\n",
    "    def forward(self, z0, logpz=None):\n",
    "        if logpz is None:\n",
    "            logpz = torch.zeros(z0.shape[0],1).to(z0.device)\n",
    "        time_tensor=torch.tensor([0.0, self.time_t], dtype=torch.float).to(z0.device)\n",
    "        state_t = odeint(\n",
    "            self.ode_func,\n",
    "            (z0, logpz),\n",
    "            time_tensor,\n",
    "            method='rk4',\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "            options={}\n",
    "        )\n",
    "        zT=state_t[0][-1]\n",
    "        logpz_T=state_t[1][-1]\n",
    "\n",
    "        return zT, logpz_T\n",
    "    #ì—­ë°©í–¥ ì ë¶„ í•™ìŠµê³¼ì •\n",
    "    def inverse(self, zT, logpz_T=None):\n",
    "        zT = zT.requires_grad_(True)\n",
    "        if logpz_T is None:\n",
    "            logpz_T = torch.zeros(zT.shape[0],1).to(zT.device)\n",
    "        time_tensor=torch.tensor([self.time_t, 0.0],dtype=torch.float).to(zT.device)\n",
    "        state_t = odeint( \n",
    "            #ìœ„ì— êµ¬í˜„í•œ ODEFunc ì‚¬ìš©           \n",
    "            self.ode_func,\n",
    "            # ODEì˜ ì´ˆê¸° ìƒíƒœ (zT, logpz_T(traceì— í•´ë‹¹))\n",
    "            (zT, logpz_T),\n",
    "            #ì‹œê°„ ì—­ë°©í–¥ìœ¼ë¡œ ì ë¶„\n",
    "            time_tensor,\n",
    "            method='rk4',\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "            options={}\n",
    "        )\n",
    "        #ê°ê° forwardztì™€ traceê°€ ì ë¶„ëœ ê²°ê³¼ ë°˜í™˜\n",
    "        z0 = state_t[0][-1]      # ìµœì¢… ìƒíƒœ z0 (t=0, ë…¸ì´ì¦ˆ)\n",
    "        logpz_0 = state_t[1][-1] # ìµœì¢… ë¡œê·¸ í™•ë¥  ë³´ì¡° í•­ (log p(x) ê³„ì‚°ì— ì‚¬ìš©)\n",
    "        \n",
    "        return z0, logpz_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8a8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í‘œì¤€ ì •ê·œë¶„í¬ì˜ ë¡œê·¸ í™•ë¥  ë°€ë„ í•¨ìˆ˜ ê³„ì‚°\n",
    "def get_logpz(z):\n",
    "    logpz = -0.5 * torch.sum(z**2, dim=1, keepdim=True) - 0.5 * z.shape[1] * torch.tensor(np.log(2 * np.pi)).to(device)\n",
    "    return logpz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adbecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (epoch, model, optimizer, train_loader, device, INPUT_DIM):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "\n",
    "\n",
    "        #ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        optimizer.zero_grad()\n",
    "        #ëª¨ë¸ì˜ ì—­ë°©í–¥ ì ë¶„ ìˆ˜í–‰(ë°ì´íƒ€ë¶„í¬->í‘œì¤€ì •ê·œë¶„í¬) ì´ z0ì´ ë‚˜ì˜¬í™•ë¥ ì„ ìµœëŒ€í™” í•´ì•¼í•œë‹¤.\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "        z0, logpz_0 = model.inverse(data)\n",
    "        #z0ì— ëŒ€í•œ í‘œì¤€ ì •ê·œë¶„í¬ì˜ ë¡œê·¸ í™•ë¥  ë°€ë„ í•¨ìˆ˜ ê³„ì‚°\n",
    "        logpz = get_logpz(z0.view(z0.size(0), -1))\n",
    "        #log p(x)= logp(z0) + log|det(dz0/dx)|(ì¦‰ -traceì˜ ì ë¶„ê°’)\n",
    "        logpx = logpz + logpz_0\n",
    "        #ë°°ì¹˜ì•ˆ ì „ì²´ì˜ lossí•¨ìˆ˜ í‰ê·  ê³„ì‚°\n",
    "        loss = -torch.mean(logpx)\n",
    "        #ì—­ì „íŒŒ\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                (100. * batch_idx)/len(train_loader),\n",
    "                loss.item()))\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch: {epoch} Average loss: {avg_loss:.6f}')\n",
    "    return avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, test_loader, device, INPUT_DIM):\n",
    "    model.eval() # í‰ê°€ ëª¨ë“œ ì„¤ì •\n",
    "    test_loss = 0\n",
    "    \n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "            # 1. Log-Likelihood ê³„ì‚°ì„ ìœ„í•´ ì—­ë³€í™˜(Inverse)ì„ ìˆ˜í–‰í•´ì•¼ í•¨\n",
    "        z0, logpz_0 = model.inverse(data)\n",
    "            \n",
    "            # 2. Log-Likelihood ê³„ì‚°\n",
    "        logpz = get_logpz(z0.view(z0.size(0), -1))\n",
    "        logpx = logpz + logpz_0\n",
    "        loss = -torch.mean(logpx)\n",
    "\n",
    "            # 3. ì†ì‹¤ ëˆ„ì  (í•œ ì—í¬í¬ ëª¨ë“  ë°°ì¹˜ì— ëŒ€í•´)\n",
    "        test_loss += loss.item()\n",
    "            \n",
    "            \n",
    "    # ë°°ì¹˜ ë³„ ì†ì‹¤ì˜ í‰ê·  ê³„ì‚°\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    print(f'====> Test set: Average loss: {avg_loss:.6f}')\n",
    "    return avg_loss # ìµœì¢… ì†ì‹¤ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74d7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FFJORD Training Started on cuda ---\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 16390.597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torch\\autograd\\graph.py:865: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:330.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 3987.237305\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2932.038086\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2598.258545\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2138.980957\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2184.477783\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1862.265137\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1778.291504\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1979.121948\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1934.015259\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1656.599365\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1622.959839\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1671.950684\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1779.286743\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1544.889893\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1636.269531\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1611.844971\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1579.648926\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1591.298584\n",
      "Epoch: 1 Average loss: 2167.016205\n",
      "====> Test set: Average loss: 1476.197446\n",
      "âœ… Loss ê°œì„  í™•ì¸: 1476.1974ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1587.954712\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1390.433594\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1381.874023\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1507.758057\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1476.369141\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1469.143799\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1384.315186\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1446.809937\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1368.916748\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1390.287109\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1317.990601\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1321.971069\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1243.234619\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1253.910645\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1444.213257\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1391.777344\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1323.804688\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1391.364990\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1232.471436\n",
      "Epoch: 2 Average loss: 1369.510496\n",
      "====> Test set: Average loss: 1272.647610\n",
      "âœ… Loss ê°œì„  í™•ì¸: 1272.6476ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1258.981079\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1235.439209\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1183.837646\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1227.698975\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1217.633057\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1281.426025\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1280.696289\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1310.944336\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1298.933350\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1206.757080\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1171.017090\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1232.513672\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1287.861206\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1263.973145\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1172.609131\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1221.101562\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1244.725830\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1285.335693\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1208.791504\n",
      "Epoch: 3 Average loss: 1240.694933\n",
      "====> Test set: Average loss: 1194.906689\n",
      "âœ… Loss ê°œì„  í™•ì¸: 1194.9067ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1189.426270\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 1152.553589\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1171.209717\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 1186.064209\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1176.098145\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1216.369019\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1177.027100\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 1218.042236\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1128.336670\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 1168.309326\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1221.815430\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 1156.171387\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1200.019409\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 1165.268677\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1123.000977\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1187.683350\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1265.751709\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 1168.605103\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1155.906982\n",
      "Epoch: 4 Average loss: 1183.776489\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m train_history.append(train_loss)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# [í‰ê°€] test í•¨ìˆ˜ í˜¸ì¶œ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m test_loss = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m test_history.append(test_loss)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_loss < best_test_loss:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(epoch, model, test_loader, device, INPUT_DIM)\u001b[39m\n\u001b[32m      2\u001b[39m model.eval() \u001b[38;5;66;03m# í‰ê°€ ëª¨ë“œ ì„¤ì •\u001b[39;00m\n\u001b[32m      3\u001b[39m test_loss = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT_DIM\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:801\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    800\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    803\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[39m, in \u001b[36mMNIST.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    143\u001b[39m img = _Image_fromarray(img.numpy(), mode=\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     img = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     target = \u001b[38;5;28mself\u001b[39m.target_transform(target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° í™˜ê²½ ì„¤ì •\n",
    "# ----------------------------------------------------------------------\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "INPUT_DIM = 28 * 28  # MNIST ì´ë¯¸ì§€ í‰íƒ„í™” í¬ê¸°\n",
    "TIME_T = 0.5         # ODE ì ë¶„ ì‹œê°„ T\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs('./logs', exist_ok=True) # ë¡œê·¸ í´ë” ìƒì„±\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
    "# ----------------------------------------------------------------------\n",
    "# (ê³ ê°ë‹˜ì˜ ODEFuncì™€ CNF í´ë˜ìŠ¤ê°€ ì´ì „ì— ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.)\n",
    "# ODEFuncëŠ” FFJORDì˜ f(z, t)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "ode_func = ODEFunc(dim=INPUT_DIM).to(device)\n",
    "ode_func = ode_func.float()\n",
    "# CNFëŠ” ODEFuncë¥¼ ë°›ì•„ odeint ì†”ë²„ë¥¼ í†µí•´ íë¦„ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "model = CNF(ode_func, T=TIME_T).to(device)\n",
    "model = model.float()\n",
    "\n",
    "# Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. ë©”ì¸ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë£¨í”„\n",
    "# ----------------------------------------------------------------------\n",
    "train_history = []\n",
    "test_history = []\n",
    "best_test_loss = float('inf')\n",
    "print(f\"--- FFJORD Training Started on {device} ---\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    \n",
    "    # [í›ˆë ¨] train í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    train_loss = train(epoch, model, optimizer, train_loader, device, INPUT_DIM)\n",
    "    train_history.append(train_loss)\n",
    "    \n",
    "    # [í‰ê°€] test í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    test_loss = test(epoch, model, test_loader, device, INPUT_DIM)\n",
    "    test_history.append(test_loss)\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'test_loss': best_test_loss,\n",
    "        }, './logs/ffjord_best_NORM.pthp') # <-- ì•ˆì •ì ì¸ ëª¨ë¸ íŒŒì¼ ì €ì¥\n",
    "        print(f\"âœ… Loss ê°œì„  í™•ì¸: {best_test_loss:.4f}ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\")\n",
    "\n",
    "print(\"--- Training Finished ---\")\n",
    "    # [ëª¨ë¸ ì €ì¥] (ì„ íƒ ì‚¬í•­)\n",
    "    # if test_loss == min(test_history):\n",
    "    #     torch.save(model.state_dict(), './logs/ffjord_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a775cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss 1075.7429ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ.\n",
      "\n",
      "âœ… ì´ë¯¸ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì–´ '16ffjord_generated_images_no_logit_fix2_.png'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# (CNF ë° ODEFunc í´ë˜ìŠ¤ëŠ” ì´ì „ì— ì •ì˜ëœ ì…€ì— ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. ì„¤ì •ê°’ ë° ëª¨ë¸ êµ¬ì¡° ì •ì˜\n",
    "# ----------------------------------------------------\n",
    "NUM_IMAGES_TO_GENERATE = 16 \n",
    "INPUT_DIM = 28 * 28 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TIME_T = 0.5 # í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ T ê°’ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ì •ì˜ (ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•´ êµ¬ì¡°ë¶€í„° ìƒì„±)\n",
    "# âš ï¸ ì£¼ì˜: ODEFuncì™€ CNF í´ë˜ìŠ¤ëŠ” ì´ ì…€ë³´ë‹¤ ìœ„ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    ode_func = ODEFunc(dim=INPUT_DIM).to(device).float()\n",
    "    model = CNF(ode_func, T=TIME_T).to(device).float()\n",
    "except NameError:\n",
    "    print(\"âŒ ì˜¤ë¥˜: ODEFunc ë˜ëŠ” CNF í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ì…€ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. í•™ìŠµëœ Loss 550 ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (í•„ìˆ˜)\n",
    "# ----------------------------------------------------\n",
    "CHECKPOINT_PATH = './logs/ffjord_best_NORM.pthp' # ğŸŸ¢ ì €ì¥ëœ Loss 550ëŒ€ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_loss = checkpoint.get('test_loss', 563.41) # test_lossê°€ ìˆìœ¼ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ 563.41 ì‚¬ìš©\n",
    "    print(f\"âœ… Loss {best_loss:.4f}ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ.\")\n",
    "    \n",
    "    # ëª¨ë¸ ê°ì²´ì— Loss ê°’ì„ ì €ì¥í•˜ì—¬ ì‹œê°í™”ì— ì‚¬ìš©\n",
    "    model.current_loss = best_loss \n",
    "except FileNotFoundError:\n",
    "    print(f\"âš ï¸ ê²½ê³ : ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ '{CHECKPOINT_PATH}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ˆê¸°í™”ëœ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    best_loss = 780.0 # ì´ˆê¸° Loss ê°’ìœ¼ë¡œ ì„¤ì •\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}. ì´ˆê¸°í™”ëœ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    best_loss = 780.0\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. ì´ë¯¸ì§€ ìƒì„± ë° ì‹œê°í™” í•¨ìˆ˜ ì •ì˜\n",
    "# ----------------------------------------------------\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# (CNF ë° ODEFunc í´ë˜ìŠ¤ëŠ” ì´ì „ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. ì´ë¯¸ì§€ ìƒì„± ë° ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ (Logit Transform ë³µì›)\n",
    "# ----------------------------------------------------\n",
    "def generate_and_visualize(model, num_images, input_dim, device):\n",
    "    \n",
    "    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "\n",
    "    # 1. Latent ë²¡í„° ìƒì„± (z0 ~ N(0, I))\n",
    "    z0 = torch.randn(num_images, input_dim).to(device).float() \n",
    "    z0.requires_grad_(True) # Trace Estimator ì‘ë™ì„ ìœ„í•´ í•„ìš”\n",
    "    # 2. logpz_0ë¥¼ ì´ˆê¸°í™” (Trace í•­)\n",
    "    zero_logpz = torch.zeros(z0.shape[0], 1).to(device).float() \n",
    "    \n",
    "    # 3. forward pass ì‹¤í–‰: x_genì€ ì •ê·œí™”ëœ [-1, 1] ë²”ìœ„ì— ìˆìŒ\n",
    "    input_tuple = (z0, zero_logpz)\n",
    "    x_gen, _ = model.forward(*input_tuple)\n",
    "    x_denorm = torch.sigmoid(x_gen)  # logit ì—­ë³€í™˜\n",
    "    x_denorm_clipped = torch.clamp(x_denorm, min=0.0, max=1.0)\n",
    "\n",
    "\n",
    "    # 4. ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³µì› (ë°”ë¡œ ìœ„ì—ì„œ ìë¥¸ ë³€ìˆ˜ ì‚¬ìš©)\n",
    "    x_images = x_denorm_clipped.detach().view(num_images, 28, 28).cpu().numpy()\n",
    "    \n",
    "    # 5. ì‹œê°í™” ë° íŒŒì¼ ì €ì¥\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    \n",
    "    # Loss ê°’ í‘œì‹œ (ë¡œë“œëœ Loss ì‚¬ìš©)\n",
    "    try:\n",
    "        loss_display = f\"Loss: {model.current_loss:.2f}\"\n",
    "    except AttributeError:\n",
    "        # ëª¨ë¸ì— current_lossê°€ ì—†ì„ ê²½ìš°ì˜ ëŒ€ì²´ ê°’ ì‚¬ìš© (ìƒˆë¡œìš´ í•™ìŠµ ì‹œ)\n",
    "        loss_display = \"Loss: N/A (New Training)\"\n",
    "        \n",
    "    plt.suptitle(f\"FFJORD Generated Images ({loss_display})\", fontsize=14)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            # vmin/vmaxë¥¼ 0ê³¼ 1ë¡œ ì„¤ì •í•˜ì—¬ ì˜¬ë°”ë¥¸ í‘ë°± ëª…ì•”ë¹„ë¡œ í‘œì‹œ\n",
    "            ax.imshow(x_images[i], cmap='gray', vmin=0, vmax=1)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # ğŸŸ¢ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥\n",
    "    output_filename = \"17ffjord_generated_images_no_logit_fix2_.png\"\n",
    "    plt.savefig(output_filename, dpi=300) \n",
    "    plt.close(fig)\n",
    "    print(f\"\\nâœ… ì´ë¯¸ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì–´ '{output_filename}'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ (ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ë§ˆì§€ë§‰ì— ì¶”ê°€)\n",
    "# ----------------------------------------------------\n",
    "generate_and_visualize(model, NUM_IMAGES_TO_GENERATE, INPUT_DIM, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
