{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torchdiffeq import  odeint\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Batch_Size = 128\n",
    "data_dir = './data'\n",
    "os.makedirs(data_dir, exist_ok=True) # ë°ì´í„° í´ë” ìƒì„±\n",
    "\n",
    "INPUT_DIM = 28 * 28 \n",
    "TIME_T = 1.0\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. FFJORD ìµœì í™” ì „ì²˜ë¦¬ ì •ì˜ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)\n",
    "# ----------------------------------------------------------------------\n",
    "# MNIST ë°ì´í„°ì˜ í‰ê· (Mean)ê³¼ í‘œì¤€í¸ì°¨(Std)ëŠ” 0.5ë¥¼ ì‚¬ìš©í•˜ì—¬ [-1, 1] ë²”ìœ„ë¡œ í‘œì¤€í™”í•©ë‹ˆë‹¤.\n",
    "class AddNoise(object):\n",
    "    def __call__(self, tensor):\n",
    "        # 0 ~ 1/256 ì‚¬ì´ì˜ ê· ë“± ë¶„í¬ ë…¸ì´ì¦ˆ ì¶”ê°€ ì¸ë±ìŠ¤ëŠ” ì—°ì†ì ì´ì—¬ì•¼ í•œë‹¤\n",
    "        return tensor\n",
    "def logit_transform(x, alpha=1e-4):\n",
    "    x = x.clamp(min=alpha, max=1-alpha)\n",
    "    return torch.log(x / (1 - x))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    AddNoise(),       # [0, 1] ë²”ìœ„ë¡œ ë³€í™˜\n",
    "    transforms.Lambda(lambda x: logit_transform(x))\n",
    "])\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. ë°ì´í„° ë¡œë” ì •ì˜ (ìˆ˜ì •ëœ transform ì ìš©)\n",
    "# ----------------------------------------------------------------------\n",
    "train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca06223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì…ë ¥ìœ¼ë¡œ f(x,t)ì™€ y, të¥¼ ë°›ì•„ í—ˆí‚¨ìŠ¨ ì¶”ì •ëŸ‰ì„ ê³„ì‚°í•´ì£¼ëŠ” í•¨ìˆ˜\n",
    "#ì—¬ëŸ¬ë²ˆ ë°˜ë³µí•˜ì—¬ í‰ê· ì„ ë‚´ì–´ ì •í™•ë„ë¥¼ ë†’ì„\n",
    "def Huchinson_estimator(forwardzt, y,  num_epsilons):\n",
    "    Batch_Size=y.shape[0]\n",
    "    grad_avg=torch.zeros(y.shape[0],1).to(device).to(y.dtype)\n",
    "    for i in range(num_epsilons):\n",
    "        epsilon=torch.randn_like(y).to(device).to(y.dtype)\n",
    "        grad = torch.autograd.grad(forwardzt, y, grad_outputs=epsilon, create_graph=True)[0]\n",
    "        trace_estimate = torch.sum(grad*epsilon, dim=1, keepdim=True)\n",
    "        grad_avg += trace_estimate\n",
    "    grad_avg /= num_epsilons\n",
    "    return grad_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67a4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tê¹Œì§€ ode solve í•´ì£¼ê³  z(t)ì™€ trace ë°˜í™˜. Huchinson_estimator ì‚¬ìš©\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(dim+1, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, dim),\n",
    "        ) \n",
    "        self.dims = dim\n",
    "\n",
    "    def forward1(self, t, x):\n",
    "        # t: scalar tensor on GPU\n",
    "        # x: (B, dim)\n",
    "        t_tensor = t.expand(x.shape[0], 1)  # repeat for batch\n",
    "        xt = torch.cat([x, t_tensor], dim=1)\n",
    "        return self.net(xt)\n",
    "    def forward(self, t, x):\n",
    "        z, logpz_T = x\n",
    "\n",
    "        # force t to GPU\n",
    "        if not torch.is_tensor(t):\n",
    "            t = torch.tensor([t], device=z.device, dtype=z.dtype)\n",
    "        else:\n",
    "            t = t.to(z.device).to(z.dtype)\n",
    "\n",
    "        z_flat = z.view(z.size(0), -1)\n",
    "\n",
    "        forwardzt = self.forward1(t, z_flat)\n",
    "        trace = Huchinson_estimator(forwardzt, z_flat, num_epsilons=12)\n",
    "\n",
    "        return forwardzt, -trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eebd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì „ì²´ ì‹ ê²½ë§\n",
    "class CNF(nn.Module):\n",
    "    def __init__(self, ode_func, T=1.0):\n",
    "        super().__init__()\n",
    "        self.ode_func = ode_func\n",
    "        self.time_t = T\n",
    "        self.rtol=1e-7\n",
    "        self.atol=1e-7\n",
    "    #ìˆœë°©í–¥ ì ë¶„ ìƒì„±ê³¼ì •\n",
    "    def forward(self, z0, logpz=None):\n",
    "        if logpz is None:\n",
    "            logpz = torch.zeros(z0.shape[0],1).to(z0.device)\n",
    "        time_tensor=torch.tensor([0.0, self.time_t], dtype=torch.float).to(z0.device)\n",
    "        state_t = odeint(\n",
    "            self.ode_func,\n",
    "            (z0, logpz),\n",
    "            time_tensor,\n",
    "            method='rk4',\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "            options={}\n",
    "        )\n",
    "        zT=state_t[0][-1]\n",
    "        logpz_T=state_t[1][-1]\n",
    "\n",
    "        return zT, logpz_T\n",
    "    #ì—­ë°©í–¥ ì ë¶„ í•™ìŠµê³¼ì •\n",
    "    def inverse(self, zT, logpz_T=None):\n",
    "        zT = zT.requires_grad_(True)\n",
    "        if logpz_T is None:\n",
    "            logpz_T = torch.zeros(zT.shape[0],1).to(zT.device)\n",
    "        time_tensor=torch.tensor([self.time_t, 0.0],dtype=torch.float).to(zT.device)\n",
    "        state_t = odeint( \n",
    "            #ìœ„ì— êµ¬í˜„í•œ ODEFunc ì‚¬ìš©           \n",
    "            self.ode_func,\n",
    "            # ODEì˜ ì´ˆê¸° ìƒíƒœ (zT, logpz_T(traceì— í•´ë‹¹))\n",
    "            (zT, logpz_T),\n",
    "            #ì‹œê°„ ì—­ë°©í–¥ìœ¼ë¡œ ì ë¶„\n",
    "            time_tensor,\n",
    "            method='rk4',\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "            options={}\n",
    "        )\n",
    "        #ê°ê° forwardztì™€ traceê°€ ì ë¶„ëœ ê²°ê³¼ ë°˜í™˜\n",
    "        z0 = state_t[0][-1]      # ìµœì¢… ìƒíƒœ z0 (t=0, ë…¸ì´ì¦ˆ)\n",
    "        logpz_0 = state_t[1][-1] # ìµœì¢… ë¡œê·¸ í™•ë¥  ë³´ì¡° í•­ (log p(x) ê³„ì‚°ì— ì‚¬ìš©)\n",
    "        \n",
    "        return z0, logpz_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f8a8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í‘œì¤€ ì •ê·œë¶„í¬ì˜ ë¡œê·¸ í™•ë¥  ë°€ë„ í•¨ìˆ˜ ê³„ì‚°\n",
    "def get_logpz(z):\n",
    "    logpz = -0.5 * torch.sum(z**2, dim=1, keepdim=True) - 0.5 * z.shape[1] * torch.tensor(np.log(2 * np.pi)).to(device)\n",
    "    return logpz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2adbecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (epoch, model, optimizer, train_loader, device, INPUT_DIM):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "\n",
    "\n",
    "        #ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        optimizer.zero_grad()\n",
    "        #ëª¨ë¸ì˜ ì—­ë°©í–¥ ì ë¶„ ìˆ˜í–‰(ë°ì´íƒ€ë¶„í¬->í‘œì¤€ì •ê·œë¶„í¬) ì´ z0ì´ ë‚˜ì˜¬í™•ë¥ ì„ ìµœëŒ€í™” í•´ì•¼í•œë‹¤.\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "        z0, logpz_0 = model.inverse(data)\n",
    "        #z0ì— ëŒ€í•œ í‘œì¤€ ì •ê·œë¶„í¬ì˜ ë¡œê·¸ í™•ë¥  ë°€ë„ í•¨ìˆ˜ ê³„ì‚°\n",
    "        logpz = get_logpz(z0.view(z0.size(0), -1))\n",
    "        #log p(x)= logp(z0) + log|det(dz0/dx)|(ì¦‰ -traceì˜ ì ë¶„ê°’)\n",
    "        logpx = logpz + logpz_0\n",
    "        #ë°°ì¹˜ì•ˆ ì „ì²´ì˜ lossí•¨ìˆ˜ í‰ê·  ê³„ì‚°\n",
    "        loss = -torch.mean(logpx)\n",
    "        #ì—­ì „íŒŒ\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                (100. * batch_idx)/len(train_loader),\n",
    "                loss.item()))\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch: {epoch} Average loss: {avg_loss:.6f}')\n",
    "    return avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, test_loader, device, INPUT_DIM):\n",
    "    model.eval() # í‰ê°€ ëª¨ë“œ ì„¤ì •\n",
    "    test_loss = 0\n",
    "    \n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "            # 1. Log-Likelihood ê³„ì‚°ì„ ìœ„í•´ ì—­ë³€í™˜(Inverse)ì„ ìˆ˜í–‰í•´ì•¼ í•¨\n",
    "        z0, logpz_0 = model.inverse(data)\n",
    "            \n",
    "            # 2. Log-Likelihood ê³„ì‚°\n",
    "        logpz = get_logpz(z0.view(z0.size(0), -1))\n",
    "        logpx = logpz + logpz_0\n",
    "        loss = -torch.mean(logpx)\n",
    "\n",
    "            # 3. ì†ì‹¤ ëˆ„ì  (í•œ ì—í¬í¬ ëª¨ë“  ë°°ì¹˜ì— ëŒ€í•´)\n",
    "        test_loss += loss.item()\n",
    "            \n",
    "            \n",
    "    # ë°°ì¹˜ ë³„ ì†ì‹¤ì˜ í‰ê·  ê³„ì‚°\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    print(f'====> Test set: Average loss: {avg_loss:.6f}')\n",
    "    return avg_loss # ìµœì¢… ì†ì‹¤ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74d7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FFJORD Training Started on cuda ---\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 13207.130859\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 4911.556641\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 4386.885742\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 4422.208984\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 4374.755859\n",
      "Epoch: 1 Average loss: 5214.500656\n",
      "====> Test set: Average loss: 4509.606201\n",
      "í˜„ì¬ í•™ìŠµë¥ : 0.000100\n",
      "âœ… Loss ê°œì„  í™•ì¸: 4509.6062ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 4482.332031\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 4302.533691\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 4131.226074\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 4180.724609\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 3929.043701\n",
      "Epoch: 2 Average loss: 4201.465130\n",
      "====> Test set: Average loss: 3838.790178\n",
      "í˜„ì¬ í•™ìŠµë¥ : 0.000050\n",
      "âœ… Loss ê°œì„  í™•ì¸: 3838.7902ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° í™˜ê²½ ì„¤ì •\n",
    "# ----------------------------------------------------------------------\n",
    "NUM_EPOCHS =2\n",
    "BATCH_SIZE = 128\n",
    "INPUT_DIM = 28 * 28  # MNIST ì´ë¯¸ì§€ í‰íƒ„í™” í¬ê¸°\n",
    "TIME_T = 1.0      # ODE ì ë¶„ ì‹œê°„ T\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs('./logs', exist_ok=True) # ë¡œê·¸ í´ë” ìƒì„±\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
    "# ----------------------------------------------------------------------\n",
    "# (ê³ ê°ë‹˜ì˜ ODEFuncì™€ CNF í´ë˜ìŠ¤ê°€ ì´ì „ì— ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.)\n",
    "# ODEFuncëŠ” FFJORDì˜ f(z, t)ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "ode_func = ODEFunc(dim=INPUT_DIM).to(device)\n",
    "ode_func = ode_func.float()\n",
    "# CNFëŠ” ODEFuncë¥¼ ë°›ì•„ odeint ì†”ë²„ë¥¼ í†µí•´ íë¦„ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "model = CNF(ode_func, T=TIME_T).to(device)\n",
    "model = model.float()\n",
    "\n",
    "# Adam ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. ë©”ì¸ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë£¨í”„\n",
    "# ----------------------------------------------------------------------\n",
    "train_history = []\n",
    "test_history = []\n",
    "best_test_loss = float('inf')\n",
    "print(f\"--- FFJORD Training Started on {device} ---\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    \n",
    "    # [í›ˆë ¨] train í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    train_loss = train(epoch, model, optimizer, train_loader, device, INPUT_DIM)\n",
    "    train_history.append(train_loss)\n",
    "    \n",
    "    # [í‰ê°€] test í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    test_loss = test(epoch, model, test_loader, device, INPUT_DIM)\n",
    "    test_history.append(test_loss)\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"í˜„ì¬ í•™ìŠµë¥ : {current_lr:.6f}\")\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'test_loss': best_test_loss,\n",
    "        }, './logs/ffjord_best111_NORM7.pth') # <-- ì•ˆì •ì ì¸ ëª¨ë¸ íŒŒì¼ ì €ì¥\n",
    "        print(f\"âœ… Loss ê°œì„  í™•ì¸: {best_test_loss:.4f}ë¡œ ëª¨ë¸ ì €ì¥ ì™„ë£Œ.\")\n",
    "\n",
    "print(\"--- Training Finished ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a775cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90ac0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loss 3838.7902ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ.\n",
      "\n",
      "âœ… ì´ë¯¸ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì–´ '33ffjord_generated_images_no_logit_fix2_.png'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# (CNF ë° ODEFunc í´ë˜ìŠ¤ëŠ” ì´ì „ì— ì •ì˜ëœ ì…€ì— ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. ì„¤ì •ê°’ ë° ëª¨ë¸ êµ¬ì¡° ì •ì˜\n",
    "# ----------------------------------------------------\n",
    "NUM_IMAGES_TO_GENERATE = 16 \n",
    "INPUT_DIM = 28 * 28 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TIME_T = 1.0 # í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ T ê°’ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ëª¨ë¸ êµ¬ì¡° ì •ì˜ (ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ê¸° ìœ„í•´ êµ¬ì¡°ë¶€í„° ìƒì„±)\n",
    "# âš ï¸ ì£¼ì˜: ODEFuncì™€ CNF í´ë˜ìŠ¤ëŠ” ì´ ì…€ë³´ë‹¤ ìœ„ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    ode_func = ODEFunc(dim=INPUT_DIM).to(device).float()\n",
    "    model = CNF(ode_func, T=TIME_T).to(device).float()\n",
    "except NameError:\n",
    "    print(\"âŒ ì˜¤ë¥˜: ODEFunc ë˜ëŠ” CNF í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ì „ ì…€ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. í•™ìŠµëœ Loss 550 ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (í•„ìˆ˜)\n",
    "# ----------------------------------------------------\n",
    "CHECKPOINT_PATH = './logs/ffjord_best111_NORM7.pth' # ğŸŸ¢ ì €ì¥ëœ Loss 550ëŒ€ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_loss = checkpoint.get('test_loss', 563.41) # test_lossê°€ ìˆìœ¼ë©´ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ 563.41 ì‚¬ìš©\n",
    "    print(f\"âœ… Loss {best_loss:.4f}ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ.\")\n",
    "    \n",
    "    # ëª¨ë¸ ê°ì²´ì— Loss ê°’ì„ ì €ì¥í•˜ì—¬ ì‹œê°í™”ì— ì‚¬ìš©\n",
    "    model.current_loss = best_loss \n",
    "except FileNotFoundError:\n",
    "    print(f\"âš ï¸ ê²½ê³ : ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ '{CHECKPOINT_PATH}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ˆê¸°í™”ëœ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    best_loss = 780.0 # ì´ˆê¸° Loss ê°’ìœ¼ë¡œ ì„¤ì •\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}. ì´ˆê¸°í™”ëœ ëª¨ë¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    best_loss = 780.0\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. ì´ë¯¸ì§€ ìƒì„± ë° ì‹œê°í™” í•¨ìˆ˜ ì •ì˜\n",
    "# ----------------------------------------------------\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# (CNF ë° ODEFunc í´ë˜ìŠ¤ëŠ” ì´ì „ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. ì´ë¯¸ì§€ ìƒì„± ë° ì‹œê°í™” í•¨ìˆ˜ ì •ì˜ (Logit Transform ë³µì›)\n",
    "# ----------------------------------------------------\n",
    "def generate_and_visualize(model, num_images, input_dim, device):\n",
    "    \n",
    "    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "\n",
    "    # 1. Latent ë²¡í„° ìƒì„± (z0 ~ N(0, I))\n",
    "    z0 = torch.randn(num_images, input_dim).to(device).float() \n",
    "    z0.requires_grad_(True) # Trace Estimator ì‘ë™ì„ ìœ„í•´ í•„ìš”\n",
    "    # 2. logpz_0ë¥¼ ì´ˆê¸°í™” (Trace í•­)\n",
    "    zero_logpz = torch.zeros(z0.shape[0], 1).to(device).float() \n",
    "    \n",
    "    # 3. forward pass ì‹¤í–‰: x_genì€ ì •ê·œí™”ëœ [-1, 1] ë²”ìœ„ì— ìˆìŒ\n",
    "    input_tuple = (z0, zero_logpz)\n",
    "    x_gen, _ = model.forward(*input_tuple)\n",
    "    x_denorm = torch.sigmoid(x_gen)  # logit ì—­ë³€í™˜\n",
    "    x_denorm_clipped = torch.clamp(x_denorm, min=0.0, max=1.0)\n",
    "\n",
    "\n",
    "    # 4. ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³µì› (ë°”ë¡œ ìœ„ì—ì„œ ìë¥¸ ë³€ìˆ˜ ì‚¬ìš©)\n",
    "    x_images = x_denorm_clipped.detach().view(num_images, 28, 28).cpu().numpy()\n",
    "    \n",
    "    # 5. ì‹œê°í™” ë° íŒŒì¼ ì €ì¥\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    \n",
    "    # Loss ê°’ í‘œì‹œ (ë¡œë“œëœ Loss ì‚¬ìš©)\n",
    "    try:\n",
    "        loss_display = f\"Loss: {model.current_loss:.2f}\"\n",
    "    except AttributeError:\n",
    "        # ëª¨ë¸ì— current_lossê°€ ì—†ì„ ê²½ìš°ì˜ ëŒ€ì²´ ê°’ ì‚¬ìš© (ìƒˆë¡œìš´ í•™ìŠµ ì‹œ)\n",
    "        loss_display = \"Loss: N/A (New Training)\"\n",
    "        \n",
    "    plt.suptitle(f\"FFJORD Generated Images ({loss_display})\", fontsize=14)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            # vmin/vmaxë¥¼ 0ê³¼ 1ë¡œ ì„¤ì •í•˜ì—¬ ì˜¬ë°”ë¥¸ í‘ë°± ëª…ì•”ë¹„ë¡œ í‘œì‹œ\n",
    "            ax.imshow(x_images[i], cmap='gray', vmin=0, vmax=1)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # ğŸŸ¢ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥\n",
    "    output_filename = \"33ffjord_generated_images_no_logit_fix2_.png\"\n",
    "    plt.savefig(output_filename, dpi=300) \n",
    "    plt.close(fig)\n",
    "    print(f\"\\nâœ… ì´ë¯¸ì§€ ìƒì„±ì´ ì™„ë£Œë˜ì–´ '{output_filename}'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. í•¨ìˆ˜ í˜¸ì¶œ ì˜ˆì‹œ (ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ ë§ˆì§€ë§‰ì— ì¶”ê°€)\n",
    "# ----------------------------------------------------\n",
    "generate_and_visualize(model, NUM_IMAGES_TO_GENERATE, INPUT_DIM, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
