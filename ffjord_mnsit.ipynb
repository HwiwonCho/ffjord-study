{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a54c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torchdiffeq import  odeint\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "Batch_Size = 128\n",
    "data_dir = './data'\n",
    "os.makedirs(data_dir, exist_ok=True) # 데이터 폴더 생성\n",
    "\n",
    "INPUT_DIM = 28 * 28 \n",
    "TIME_T = 1.0\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. FFJORD 최적화 전처리 정의 (핵심 수정 부분)\n",
    "# ----------------------------------------------------------------------\n",
    "# MNIST 데이터의 평균(Mean)과 표준편차(Std)는 0.5를 사용하여 [-1, 1] 범위로 표준화합니다.\n",
    "class AddNoise(object):\n",
    "    def __call__(self, tensor):\n",
    "        # 0 ~ 1/256 사이의 균등 분포 노이즈 추가 인덱스는 연속적이여야 한다\n",
    "        return tensor + torch.rand_like(tensor) / 128.0\n",
    "def logit_transform(x, alpha=1e-4):\n",
    "    x = x.clamp(min=alpha, max=1-alpha)\n",
    "    return torch.log(x / (1 - x))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    AddNoise(),       # [0, 1] 범위로 변환\n",
    "    transforms.Lambda(lambda x: logit_transform(x))\n",
    "])\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. 데이터 로더 정의 (수정된 transform 적용)\n",
    "# ----------------------------------------------------------------------\n",
    "train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca06223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력으로 f(x,t)와 y, t를 받아 허킨슨 추정량을 계산해주는 함수\n",
    "#여러번 반복하여 평균을 내어 정확도를 높임\n",
    "def Huchinson_estimator(forwardzt, y,  num_epsilons):\n",
    "    Batch_Size=y.shape[0]\n",
    "    grad_avg=torch.zeros(y.shape[0],1).to(device).to(y.dtype)\n",
    "    for i in range(num_epsilons):\n",
    "        epsilon=torch.randn_like(y).to(device).to(y.dtype)\n",
    "        grad = torch.autograd.grad(forwardzt, y, grad_outputs=epsilon, create_graph=True)[0]\n",
    "        trace_estimate = torch.sum(grad*epsilon, dim=1, keepdim=True)\n",
    "        grad_avg += trace_estimate\n",
    "    grad_avg /= num_epsilons\n",
    "    return grad_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t까지 ode solve 해주고 z(t)와 trace 반환. Huchinson_estimator 사용\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(dim+1, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, dim),\n",
    "        ) \n",
    "        self.dims = dim\n",
    "\n",
    "    def forward1(self, t, x):\n",
    "        # t: scalar tensor on GPU\n",
    "        # x: (B, dim)\n",
    "        t_tensor = t.expand(x.shape[0], 1)  # repeat for batch\n",
    "        xt = torch.cat([x, t_tensor], dim=1)\n",
    "        return self.net(xt)\n",
    "    def forward(self, t, x):\n",
    "        z, logpz_T = x\n",
    "\n",
    "        # force t to GPU\n",
    "        if not torch.is_tensor(t):\n",
    "            t = torch.tensor([t], device=z.device, dtype=z.dtype)\n",
    "        else:\n",
    "            t = t.to(z.device).to(z.dtype)\n",
    "\n",
    "        z_flat = z.view(z.size(0), -1)\n",
    "\n",
    "        forwardzt = self.forward1(t, z_flat)\n",
    "        trace = Huchinson_estimator(forwardzt, z_flat, num_epsilons=12)\n",
    "\n",
    "        return forwardzt, -trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eebd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 신경망\n",
    "class CNF(nn.Module):\n",
    "    def __init__(self, ode_func, T=1.0):\n",
    "        super().__init__()\n",
    "        self.ode_func = ode_func\n",
    "        self.time_t = T\n",
    "        self.rtol=1e-6\n",
    "        self.atol=1e-6\n",
    "    #순방향 적분 생성과정\n",
    "    def forward(self, z0, logpz=None):\n",
    "        if logpz is None:\n",
    "            logpz = torch.zeros(z0.shape[0],1).to(z0.device)\n",
    "        time_tensor=torch.tensor([0.0, self.time_t], dtype=torch.float).to(z0.device)\n",
    "        state_t = odeint(\n",
    "            self.ode_func,\n",
    "            (z0, logpz),\n",
    "            time_tensor,\n",
    "            method='rk4',\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "            options={}\n",
    "        )\n",
    "        zT=state_t[0][-1]\n",
    "        logpz_T=state_t[1][-1]\n",
    "\n",
    "        return zT, logpz_T\n",
    "    #역방향 적분 학습과정\n",
    "    def inverse(self, zT, logpz_T=None):\n",
    "        zT = zT.requires_grad_(True)\n",
    "        if logpz_T is None:\n",
    "            logpz_T = torch.zeros(zT.shape[0],1).to(zT.device)\n",
    "        time_tensor=torch.tensor([self.time_t, 0.0],dtype=torch.float).to(zT.device)\n",
    "        state_t = odeint( \n",
    "            #위에 구현한 ODEFunc 사용           \n",
    "            self.ode_func,\n",
    "            # ODE의 초기 상태 (zT, logpz_T(trace에 해당))\n",
    "            (zT, logpz_T),\n",
    "            #시간 역방향으로 적분\n",
    "            time_tensor,\n",
    "            method='rk4',\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "            options={}\n",
    "        )\n",
    "        #각각 forwardzt와 trace가 적분된 결과 반환\n",
    "        z0 = state_t[0][-1]      # 최종 상태 z0 (t=0, 노이즈)\n",
    "        logpz_0 = state_t[1][-1] # 최종 로그 확률 보조 항 (log p(x) 계산에 사용)\n",
    "        \n",
    "        return z0, logpz_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8a8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#표준 정규분포의 로그 확률 밀도 함수 계산\n",
    "def get_logpz(z):\n",
    "    logpz = -0.5 * torch.sum(z**2, dim=1, keepdim=True) - 0.5 * z.shape[1] * torch.tensor(np.log(2 * np.pi)).to(device)\n",
    "    return logpz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adbecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (epoch, model, optimizer, train_loader, device, INPUT_DIM):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "\n",
    "\n",
    "        #기울기 초기화\n",
    "        optimizer.zero_grad()\n",
    "        #모델의 역방향 적분 수행(데이타분포->표준정규분포) 이 z0이 나올확률을 최대화 해야한다.\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "        z0, logpz_0 = model.inverse(data)\n",
    "        #z0에 대한 표준 정규분포의 로그 확률 밀도 함수 계산\n",
    "        logpz = get_logpz(z0.view(z0.size(0), -1))\n",
    "        #log p(x)= logp(z0) + log|det(dz0/dx)|(즉 -trace의 적분값)\n",
    "        logpx = logpz + logpz_0\n",
    "        #배치안 전체의 loss함수 평균 계산\n",
    "        loss = -torch.mean(logpx)\n",
    "        #역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                (100. * batch_idx)/len(train_loader),\n",
    "                loss.item()))\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f'Epoch: {epoch} Average loss: {avg_loss:.6f}')\n",
    "    return avg_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5052a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, test_loader, device, INPUT_DIM):\n",
    "    model.eval() # 평가 모드 설정\n",
    "    test_loss = 0\n",
    "    \n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "        data = data.view(data.shape[0], INPUT_DIM)\n",
    "            # 1. Log-Likelihood 계산을 위해 역변환(Inverse)을 수행해야 함\n",
    "        z0, logpz_0 = model.inverse(data)\n",
    "            \n",
    "            # 2. Log-Likelihood 계산\n",
    "        logpz = get_logpz(z0.view(z0.size(0), -1))\n",
    "        logpx = logpz + logpz_0\n",
    "        loss = -torch.mean(logpx)\n",
    "\n",
    "            # 3. 손실 누적 (한 에포크 모든 배치에 대해)\n",
    "        test_loss += loss.item()\n",
    "            \n",
    "            \n",
    "    # 배치 별 손실의 평균 계산\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    print(f'====> Test set: Average loss: {avg_loss:.6f}')\n",
    "    return avg_loss # 최종 손실 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FFJORD Training Started on cuda ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harryjo\\Desktop\\hwiwon ffjord\\venv313\\Lib\\site-packages\\torch\\autograd\\graph.py:865: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:330.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 13255.857422\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2699.199219\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2040.000244\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1700.816162\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1537.409058\n",
      "Epoch: 1 Average loss: 2389.859233\n",
      "====> Test set: Average loss: 1464.762833\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 1464.7628로 모델 저장 완료.\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1484.723755\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1360.108032\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1322.970703\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1261.463623\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1248.843994\n",
      "Epoch: 2 Average loss: 1313.518236\n",
      "====> Test set: Average loss: 1189.959466\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 1189.9595로 모델 저장 완료.\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1183.411133\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1172.888672\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1156.315186\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1113.341309\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1080.690063\n",
      "Epoch: 3 Average loss: 1129.360558\n",
      "====> Test set: Average loss: 1060.293356\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 1060.2934로 모델 저장 완료.\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1055.189209\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1047.501099\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1014.703918\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1020.897705\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1000.012939\n",
      "Epoch: 4 Average loss: 1019.041804\n",
      "====> Test set: Average loss: 972.113375\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 972.1134로 모델 저장 완료.\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 964.362793\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 975.108215\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 937.996948\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 946.776794\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 912.867981\n",
      "Epoch: 5 Average loss: 937.909182\n",
      "====> Test set: Average loss: 895.931209\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 895.9312로 모델 저장 완료.\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 906.270264\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 890.705872\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 883.245361\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 847.202271\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 854.970398\n",
      "Epoch: 6 Average loss: 872.453486\n",
      "====> Test set: Average loss: 840.181138\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 840.1811로 모델 저장 완료.\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 849.012573\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 844.987183\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 823.569702\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 801.275024\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 802.933044\n",
      "Epoch: 7 Average loss: 822.556913\n",
      "====> Test set: Average loss: 796.742416\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 796.7424로 모델 저장 완료.\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 801.928589\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 820.759277\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 775.149719\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 782.111145\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 769.486816\n",
      "Epoch: 8 Average loss: 782.983756\n",
      "====> Test set: Average loss: 761.492396\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 761.4924로 모델 저장 완료.\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 765.304138\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 773.339600\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 761.661987\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 774.537659\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 744.106079\n",
      "Epoch: 9 Average loss: 751.211787\n",
      "====> Test set: Average loss: 733.703195\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 733.7032로 모델 저장 완료.\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 737.858887\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 752.979614\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 731.954163\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 720.691772\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 716.179810\n",
      "Epoch: 10 Average loss: 727.064177\n",
      "====> Test set: Average loss: 712.437793\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 712.4378로 모델 저장 완료.\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 730.249084\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 716.090820\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 702.373657\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 713.973816\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 688.642578\n",
      "Epoch: 11 Average loss: 707.796369\n",
      "====> Test set: Average loss: 696.884652\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 696.8847로 모델 저장 완료.\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 704.179871\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 702.402588\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 685.761719\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 709.409180\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 680.725403\n",
      "Epoch: 12 Average loss: 692.636552\n",
      "====> Test set: Average loss: 683.882931\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 683.8829로 모델 저장 완료.\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 684.700684\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 696.272766\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 691.954041\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 686.460571\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 662.933594\n",
      "Epoch: 13 Average loss: 681.273108\n",
      "====> Test set: Average loss: 671.484054\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 671.4841로 모델 저장 완료.\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 657.017578\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 667.844421\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 671.932800\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 672.103088\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 666.586731\n",
      "Epoch: 14 Average loss: 671.635194\n",
      "====> Test set: Average loss: 663.627234\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 663.6272로 모델 저장 완료.\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 663.550781\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 670.950806\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 649.462769\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 663.065369\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 653.993652\n",
      "Epoch: 15 Average loss: 664.367129\n",
      "====> Test set: Average loss: 655.675162\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 655.6752로 모델 저장 완료.\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 669.536316\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 671.881836\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 652.645447\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 653.664062\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 654.063721\n",
      "Epoch: 16 Average loss: 658.593181\n",
      "====> Test set: Average loss: 653.517604\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 653.5176로 모델 저장 완료.\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 664.372742\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 655.511414\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 649.951172\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 648.752869\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 657.725647\n",
      "Epoch: 17 Average loss: 653.162310\n",
      "====> Test set: Average loss: 649.476121\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 649.4761로 모델 저장 완료.\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 647.493164\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 637.573730\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 649.421875\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 666.379639\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 644.756714\n",
      "Epoch: 18 Average loss: 648.125010\n",
      "====> Test set: Average loss: 642.920684\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 642.9207로 모델 저장 완료.\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 648.583923\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 648.148010\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 658.029419\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 643.656616\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 647.629822\n",
      "Epoch: 19 Average loss: 643.879723\n",
      "====> Test set: Average loss: 639.948539\n",
      "현재 학습률: 0.000500\n",
      "✅ Loss 개선 확인: 639.9485로 모델 저장 완료.\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 644.415161\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 640.639709\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 648.613586\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 646.908691\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 635.700989\n",
      "Epoch: 20 Average loss: 639.932730\n",
      "====> Test set: Average loss: 639.905163\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 639.9052로 모델 저장 완료.\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 634.395264\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 626.100403\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 644.627930\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 616.293152\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 615.731140\n",
      "Epoch: 21 Average loss: 622.767683\n",
      "====> Test set: Average loss: 617.903398\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 617.9034로 모델 저장 완료.\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 611.623962\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 618.080444\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 632.668213\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 613.684570\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 618.272400\n",
      "Epoch: 22 Average loss: 620.038938\n",
      "====> Test set: Average loss: 618.191789\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 617.378723\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 622.731873\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 631.130676\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 614.140076\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 614.739563\n",
      "Epoch: 23 Average loss: 617.087763\n",
      "====> Test set: Average loss: 613.171079\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 613.1711로 모델 저장 완료.\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 614.254639\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 608.582336\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 632.659546\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 607.410645\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 611.012817\n",
      "Epoch: 24 Average loss: 613.554938\n",
      "====> Test set: Average loss: 608.060784\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 608.0608로 모델 저장 완료.\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 608.200562\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 613.829468\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 613.666016\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 608.351196\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 616.931152\n",
      "Epoch: 25 Average loss: 610.180923\n",
      "====> Test set: Average loss: 607.839095\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 607.8391로 모델 저장 완료.\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 608.521729\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 595.336914\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 975.384644\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 772.760376\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 683.892334\n",
      "Epoch: 26 Average loss: 814.670350\n",
      "====> Test set: Average loss: 667.580563\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 662.548828\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 645.504089\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 633.562317\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 630.233276\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 640.796143\n",
      "Epoch: 27 Average loss: 642.449663\n",
      "====> Test set: Average loss: 623.619352\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 615.006348\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 610.151367\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 620.384033\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 605.759277\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 625.509705\n",
      "Epoch: 28 Average loss: 621.365773\n",
      "====> Test set: Average loss: 614.005677\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 615.660156\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 625.746460\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 624.750122\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 619.238159\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 636.006409\n",
      "Epoch: 29 Average loss: 613.645954\n",
      "====> Test set: Average loss: 606.624577\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 606.6246로 모델 저장 완료.\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 632.664368\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 615.234253\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 618.593445\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 622.290527\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 591.517273\n",
      "Epoch: 30 Average loss: 607.141942\n",
      "====> Test set: Average loss: 602.334922\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 602.3349로 모델 저장 완료.\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 599.384521\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 600.460510\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 583.751343\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 604.169312\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 602.911133\n",
      "Epoch: 31 Average loss: 601.370419\n",
      "====> Test set: Average loss: 597.056546\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 597.0565로 모델 저장 완료.\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 590.885681\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 600.002197\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 587.682495\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 602.515442\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 596.878906\n",
      "Epoch: 32 Average loss: 595.577412\n",
      "====> Test set: Average loss: 590.236388\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 590.2364로 모델 저장 완료.\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 587.420410\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 5749.953613\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 930.521851\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 767.684631\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 728.058472\n",
      "Epoch: 33 Average loss: 894.257967\n",
      "====> Test set: Average loss: 684.904821\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 687.806641\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 663.214661\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 649.156860\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 656.104126\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 632.829590\n",
      "Epoch: 34 Average loss: 647.347025\n",
      "====> Test set: Average loss: 618.755257\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 624.258850\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 613.259644\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 613.911072\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 615.791809\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 594.663086\n",
      "Epoch: 35 Average loss: 612.622390\n",
      "====> Test set: Average loss: 602.682393\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 600.156494\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 608.931091\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 596.801819\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 597.330078\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 599.871460\n",
      "Epoch: 36 Average loss: 600.439914\n",
      "====> Test set: Average loss: 593.816964\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 596.411987\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 601.937866\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 600.572388\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 585.293213\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 585.428833\n",
      "Epoch: 37 Average loss: 593.344264\n",
      "====> Test set: Average loss: 587.063776\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 587.0638로 모델 저장 완료.\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 586.162048\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 585.579590\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 594.168640\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 585.643433\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 574.438477\n",
      "Epoch: 38 Average loss: 587.265275\n",
      "====> Test set: Average loss: 584.300714\n",
      "현재 학습률: 0.000250\n",
      "✅ Loss 개선 확인: 584.3007로 모델 저장 완료.\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 581.577454\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 588.552124\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 1201.004272\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 1004.915283\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 870.070923\n",
      "Epoch: 39 Average loss: 1051.691977\n",
      "====> Test set: Average loss: 823.531354\n",
      "현재 학습률: 0.000250\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 819.967224\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 785.534851\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 729.714905\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 688.537598\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 691.437439\n",
      "Epoch: 40 Average loss: 733.890305\n",
      "====> Test set: Average loss: 672.144212\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 679.274292\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 664.818420\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 654.178589\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 634.253357\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 663.665405\n",
      "Epoch: 41 Average loss: 656.575164\n",
      "====> Test set: Average loss: 639.952019\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 639.181030\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 643.683044\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 624.669312\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 637.790466\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 613.222046\n",
      "Epoch: 42 Average loss: 633.479046\n",
      "====> Test set: Average loss: 621.987982\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 612.709595\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 615.109741\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 631.685669\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 614.902344\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 602.923340\n",
      "Epoch: 43 Average loss: 619.401808\n",
      "====> Test set: Average loss: 610.984469\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 626.697083\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 621.559753\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 598.235840\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 605.964600\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 597.351929\n",
      "Epoch: 44 Average loss: 608.529080\n",
      "====> Test set: Average loss: 599.875612\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 597.433716\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 603.579468\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 590.897583\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 599.616638\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 605.509705\n",
      "Epoch: 45 Average loss: 599.495765\n",
      "====> Test set: Average loss: 592.791844\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 585.174316\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 598.674744\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 589.482056\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 593.275391\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 584.383728\n",
      "Epoch: 46 Average loss: 593.125921\n",
      "====> Test set: Average loss: 587.254189\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 589.511353\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 591.558228\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 591.204956\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 582.913574\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 595.542236\n",
      "Epoch: 47 Average loss: 587.557675\n",
      "====> Test set: Average loss: 582.706364\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 582.7064로 모델 저장 완료.\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 593.053711\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 590.847534\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 594.486267\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 601.966064\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 562.769897\n",
      "Epoch: 48 Average loss: 582.089558\n",
      "====> Test set: Average loss: 577.979427\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 577.9794로 모델 저장 완료.\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 582.187561\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 587.681030\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 583.024048\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 565.583801\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 590.344788\n",
      "Epoch: 49 Average loss: 576.767282\n",
      "====> Test set: Average loss: 575.120195\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 575.1202로 모델 저장 완료.\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 590.561279\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 580.992615\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 580.588379\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 578.072876\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 563.423096\n",
      "Epoch: 50 Average loss: 572.103210\n",
      "====> Test set: Average loss: 567.648820\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 567.6488로 모델 저장 완료.\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 562.762573\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 559.828857\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 576.526489\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 573.317139\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 561.940979\n",
      "Epoch: 51 Average loss: 567.892167\n",
      "====> Test set: Average loss: 563.044859\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 563.0449로 모델 저장 완료.\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 558.504700\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 558.898438\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 556.037109\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 558.989014\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 552.051147\n",
      "Epoch: 52 Average loss: 563.426907\n",
      "====> Test set: Average loss: 559.383064\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 559.3831로 모델 저장 완료.\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 559.282104\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 560.491882\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 569.023315\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 561.875244\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 563.762939\n",
      "Epoch: 53 Average loss: 557.801979\n",
      "====> Test set: Average loss: 553.727000\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 553.7270로 모델 저장 완료.\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 553.177490\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 540.149658\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 556.828613\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 548.687622\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 556.726501\n",
      "Epoch: 54 Average loss: 553.265166\n",
      "====> Test set: Average loss: 548.672624\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 548.6726로 모델 저장 완료.\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 548.928467\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 538.588440\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 559.568176\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 541.613281\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 541.433289\n",
      "Epoch: 55 Average loss: 548.597093\n",
      "====> Test set: Average loss: 546.561218\n",
      "현재 학습률: 0.000125\n",
      "✅ Loss 개선 확인: 546.5612로 모델 저장 완료.\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 560.784363\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 541.143677\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 551.631958\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 538.391357\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 1203.837891\n",
      "Epoch: 56 Average loss: 868.777405\n",
      "====> Test set: Average loss: 972.425187\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 1001.343872\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 836.074097\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 762.975281\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 669.488831\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 628.941650\n",
      "Epoch: 57 Average loss: 744.705745\n",
      "====> Test set: Average loss: 625.163967\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 622.781921\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 624.801453\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 595.915527\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 596.517456\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 583.153870\n",
      "Epoch: 58 Average loss: 601.917946\n",
      "====> Test set: Average loss: 581.756256\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 576.755249\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 581.709961\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 581.272156\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 576.872009\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 581.852661\n",
      "Epoch: 59 Average loss: 576.678675\n",
      "====> Test set: Average loss: 568.278578\n",
      "현재 학습률: 0.000125\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 588.609070\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 576.957214\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 559.660522\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 557.876221\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 563.077759\n",
      "Epoch: 60 Average loss: 566.027975\n",
      "====> Test set: Average loss: 559.081742\n",
      "현재 학습률: 0.000063\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 554.789612\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 554.062500\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 549.772827\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 569.738708\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 559.510498\n",
      "Epoch: 61 Average loss: 556.046540\n",
      "====> Test set: Average loss: 551.342502\n",
      "현재 학습률: 0.000063\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 552.768677\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 561.555664\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 554.320251\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 543.625183\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 545.147705\n",
      "Epoch: 62 Average loss: 551.323828\n",
      "====> Test set: Average loss: 547.585726\n",
      "현재 학습률: 0.000063\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 556.542725\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 534.603516\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 545.934082\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 547.853088\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 543.028503\n",
      "Epoch: 63 Average loss: 547.758930\n",
      "====> Test set: Average loss: 543.361167\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 543.3612로 모델 저장 완료.\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 561.352844\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 557.332764\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 564.383362\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 533.776978\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 551.931396\n",
      "Epoch: 64 Average loss: 545.111364\n",
      "====> Test set: Average loss: 541.441771\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 541.4418로 모델 저장 완료.\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 531.964722\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 551.861755\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 541.946289\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 528.562988\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 547.245239\n",
      "Epoch: 65 Average loss: 542.662424\n",
      "====> Test set: Average loss: 538.680316\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 538.6803로 모델 저장 완료.\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 543.596924\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 543.998474\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 555.313232\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 543.036926\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 525.393616\n",
      "Epoch: 66 Average loss: 539.598953\n",
      "====> Test set: Average loss: 535.831008\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 535.8310로 모델 저장 완료.\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 529.348877\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 529.752991\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 520.627563\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 539.320862\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 540.854736\n",
      "Epoch: 67 Average loss: 534.345754\n",
      "====> Test set: Average loss: 528.324346\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 528.3243로 모델 저장 완료.\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 543.160645\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 514.899292\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 542.215210\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 528.736755\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 523.685669\n",
      "Epoch: 68 Average loss: 529.163755\n",
      "====> Test set: Average loss: 525.986011\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 525.9860로 모델 저장 완료.\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 514.823914\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 528.203491\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 530.333374\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 523.837036\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 519.891235\n",
      "Epoch: 69 Average loss: 525.860974\n",
      "====> Test set: Average loss: 521.346747\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 521.3467로 모델 저장 완료.\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 528.767700\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 517.716858\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 515.072327\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 519.809631\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 533.106323\n",
      "Epoch: 70 Average loss: 522.728830\n",
      "====> Test set: Average loss: 519.903449\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 519.9034로 모델 저장 완료.\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 512.699951\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 511.255981\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 529.539429\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 512.850159\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 531.078979\n",
      "Epoch: 71 Average loss: 519.658644\n",
      "====> Test set: Average loss: 515.812895\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 515.8129로 모델 저장 완료.\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 522.852539\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 505.710388\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 526.535278\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 513.410217\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 522.243103\n",
      "Epoch: 72 Average loss: 516.903611\n",
      "====> Test set: Average loss: 512.861138\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 512.8611로 모델 저장 완료.\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 522.987488\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 528.233215\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 516.187500\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 527.475647\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 518.093262\n",
      "Epoch: 73 Average loss: 514.234787\n",
      "====> Test set: Average loss: 510.669662\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 510.6697로 모델 저장 완료.\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 511.885193\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 517.295898\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 507.852112\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 496.573792\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 509.447540\n",
      "Epoch: 74 Average loss: 511.469286\n",
      "====> Test set: Average loss: 508.373562\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 508.3736로 모델 저장 완료.\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 506.764740\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 520.736816\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 512.234619\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 520.524353\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 500.229523\n",
      "Epoch: 75 Average loss: 508.631148\n",
      "====> Test set: Average loss: 505.022794\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 505.0228로 모델 저장 완료.\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 497.857422\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 506.684052\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 511.266998\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 511.078979\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 507.249664\n",
      "Epoch: 76 Average loss: 506.167866\n",
      "====> Test set: Average loss: 503.370721\n",
      "현재 학습률: 0.000063\n",
      "✅ Loss 개선 확인: 503.3707로 모델 저장 완료.\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 499.753815\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 504.534058\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 493.742279\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 501.726349\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 7027.760742\n",
      "Epoch: 77 Average loss: 705.428807\n",
      "====> Test set: Average loss: 827.157889\n",
      "현재 학습률: 0.000063\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 842.369812\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 585.455261\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 539.774048\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 534.022461\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 529.797363\n",
      "Epoch: 78 Average loss: 576.263952\n",
      "====> Test set: Average loss: 520.508926\n",
      "현재 학습률: 0.000063\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 536.757385\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 525.015930\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 521.157104\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 505.083984\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 514.702454\n",
      "Epoch: 79 Average loss: 516.537150\n",
      "====> Test set: Average loss: 510.030047\n",
      "현재 학습률: 0.000063\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 511.459167\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 510.961517\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 526.032349\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 504.019836\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 510.468079\n",
      "Epoch: 80 Average loss: 510.315759\n",
      "====> Test set: Average loss: 504.120675\n",
      "현재 학습률: 0.000031\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 495.943878\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 514.166748\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 486.679779\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 499.441071\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 494.832703\n",
      "Epoch: 81 Average loss: 502.216705\n",
      "====> Test set: Average loss: 497.769082\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 497.7691로 모델 저장 완료.\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 497.563019\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 498.163086\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 502.825439\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 491.922180\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 496.373596\n",
      "Epoch: 82 Average loss: 498.380036\n",
      "====> Test set: Average loss: 494.988855\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 494.9889로 모델 저장 완료.\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 492.667023\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 488.381653\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 488.601929\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 503.319214\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 498.736267\n",
      "Epoch: 83 Average loss: 496.604949\n",
      "====> Test set: Average loss: 493.823291\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 493.8233로 모델 저장 완료.\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 498.915558\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 492.781433\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 499.690674\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 499.418823\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 499.455994\n",
      "Epoch: 84 Average loss: 495.330213\n",
      "====> Test set: Average loss: 491.908988\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 491.9090로 모델 저장 완료.\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 501.876190\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 500.854065\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 484.048950\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 497.501953\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 487.292969\n",
      "Epoch: 85 Average loss: 494.013528\n",
      "====> Test set: Average loss: 493.169236\n",
      "현재 학습률: 0.000031\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 515.791077\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 538.276733\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 506.115021\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 502.020203\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 485.246429\n",
      "Epoch: 86 Average loss: 496.503387\n",
      "====> Test set: Average loss: 491.295537\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 491.2955로 모델 저장 완료.\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 504.322571\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 486.001770\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 480.241333\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 501.401062\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 488.674103\n",
      "Epoch: 87 Average loss: 492.002987\n",
      "====> Test set: Average loss: 488.837710\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 488.8377로 모델 저장 완료.\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 486.964172\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 511.888184\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 492.037842\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 493.941345\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 491.008698\n",
      "Epoch: 88 Average loss: 490.997113\n",
      "====> Test set: Average loss: 488.118634\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 488.1186로 모델 저장 완료.\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 491.446167\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 491.228760\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 493.347870\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 482.412537\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 495.162842\n",
      "Epoch: 89 Average loss: 489.512199\n",
      "====> Test set: Average loss: 494.826958\n",
      "현재 학습률: 0.000031\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 488.400909\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 500.337982\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 481.078674\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 483.781921\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 492.942108\n",
      "Epoch: 90 Average loss: 488.625335\n",
      "====> Test set: Average loss: 485.792226\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 485.7922로 모델 저장 완료.\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 486.468933\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 489.705566\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 485.903656\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 492.812622\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 486.200867\n",
      "Epoch: 91 Average loss: 486.887469\n",
      "====> Test set: Average loss: 484.304633\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 484.3046로 모델 저장 완료.\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 489.992859\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 477.633972\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 497.780731\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 486.827942\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 475.933167\n",
      "Epoch: 92 Average loss: 485.624799\n",
      "====> Test set: Average loss: 482.437685\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 482.4377로 모델 저장 완료.\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 486.755219\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 480.189270\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 472.571167\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 474.803650\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 481.256317\n",
      "Epoch: 93 Average loss: 483.895639\n",
      "====> Test set: Average loss: 481.227060\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 481.2271로 모델 저장 완료.\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 488.826660\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 492.429688\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 471.827942\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 468.468475\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 476.267578\n",
      "Epoch: 94 Average loss: 482.423474\n",
      "====> Test set: Average loss: 479.526950\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 479.5270로 모델 저장 완료.\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 481.607239\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 493.190399\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 493.234528\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 479.293732\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 490.549774\n",
      "Epoch: 95 Average loss: 480.940539\n",
      "====> Test set: Average loss: 477.668150\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 477.6681로 모델 저장 완료.\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 479.125854\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 475.212830\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 481.530212\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 483.632111\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 466.525940\n",
      "Epoch: 96 Average loss: 479.455936\n",
      "====> Test set: Average loss: 477.129073\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 477.1291로 모델 저장 완료.\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 477.542511\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 470.378113\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 482.674530\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 483.729950\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 465.122131\n",
      "Epoch: 97 Average loss: 478.115643\n",
      "====> Test set: Average loss: 475.288473\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 475.2885로 모델 저장 완료.\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 483.712494\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 475.847595\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 470.861115\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 478.059021\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 473.314484\n",
      "Epoch: 98 Average loss: 476.301960\n",
      "====> Test set: Average loss: 473.887329\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 473.8873로 모델 저장 완료.\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 469.790100\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 474.341461\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 483.630005\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 477.137299\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 480.029205\n",
      "Epoch: 99 Average loss: 474.815819\n",
      "====> Test set: Average loss: 472.303997\n",
      "현재 학습률: 0.000031\n",
      "✅ Loss 개선 확인: 472.3040로 모델 저장 완료.\n",
      "Train Epoch: 100 [0/60000 (0%)]\tLoss: 472.930969\n",
      "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 488.389160\n",
      "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 472.966492\n",
      "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 485.619873\n",
      "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 489.671661\n",
      "Epoch: 100 Average loss: 473.841889\n",
      "====> Test set: Average loss: 472.321140\n",
      "현재 학습률: 0.000016\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. 하이퍼파라미터 및 환경 설정\n",
    "# ----------------------------------------------------------------------\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "INPUT_DIM = 28 * 28  # MNIST 이미지 평탄화 크기\n",
    "TIME_T = 1.0      # ODE 적분 시간 T\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs('./logs', exist_ok=True) # 로그 폴더 생성\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. 모델 및 옵티마이저 초기화\n",
    "# ----------------------------------------------------------------------\n",
    "# (고객님의 ODEFunc와 CNF 클래스가 이전에 정의되어 있다고 가정합니다.)\n",
    "# ODEFunc는 FFJORD의 f(z, t)를 정의합니다.\n",
    "ode_func = ODEFunc(dim=INPUT_DIM).to(device)\n",
    "ode_func = ode_func.float()\n",
    "# CNF는 ODEFunc를 받아 odeint 솔버를 통해 흐름을 관리합니다.\n",
    "model = CNF(ode_func, T=TIME_T).to(device)\n",
    "model = model.float()\n",
    "\n",
    "# Adam 옵티마이저 사용\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. 메인 학습 및 테스트 루프\n",
    "# ----------------------------------------------------------------------\n",
    "train_history = []\n",
    "test_history = []\n",
    "best_test_loss = float('inf')\n",
    "print(f\"--- FFJORD Training Started on {device} ---\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    \n",
    "    # [훈련] train 함수 호출\n",
    "    train_loss = train(epoch, model, optimizer, train_loader, device, INPUT_DIM)\n",
    "    train_history.append(train_loss)\n",
    "    \n",
    "    # [평가] test 함수 호출\n",
    "    test_loss = test(epoch, model, test_loader, device, INPUT_DIM)\n",
    "    test_history.append(test_loss)\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"현재 학습률: {current_lr:.6f}\")\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'test_loss': best_test_loss,\n",
    "        }, './logs/ffjord_best111_NORM7.pth') # <-- 안정적인 모델 파일 저장\n",
    "        print(f\"✅ Loss 개선 확인: {best_test_loss:.4f}로 모델 저장 완료.\")\n",
    "\n",
    "print(\"--- Training Finished ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a775cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loss 472.3040의 모델 가중치 로드 성공.\n",
      "\n",
      "✅ 이미지 생성이 완료되어 '27ffjord_generated_images_no_logit_fix2_.png'으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# (CNF 및 ODEFunc 클래스는 이전에 정의된 셀에 존재해야 합니다.)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. 설정값 및 모델 구조 정의\n",
    "# ----------------------------------------------------\n",
    "NUM_IMAGES_TO_GENERATE = 16 \n",
    "INPUT_DIM = 28 * 28 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TIME_T = 1.0 # 훈련 시 사용한 T 값과 일치해야 합니다.\n",
    "\n",
    "# 모델 구조 정의 (가중치를 로드하기 위해 구조부터 생성)\n",
    "# ⚠️ 주의: ODEFunc와 CNF 클래스는 이 셀보다 위에 정의되어 있어야 합니다.\n",
    "try:\n",
    "    ode_func = ODEFunc(dim=INPUT_DIM).to(device).float()\n",
    "    model = CNF(ode_func, T=TIME_T).to(device).float()\n",
    "except NameError:\n",
    "    print(\"❌ 오류: ODEFunc 또는 CNF 클래스가 정의되지 않았습니다. 이전 셀을 실행해 주세요.\")\n",
    "    exit()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. 학습된 Loss 550 모델 가중치 로드 (필수)\n",
    "# ----------------------------------------------------\n",
    "CHECKPOINT_PATH = './logs/ffjord_best111_NORM7.pth' # 🟢 저장된 Loss 550대 모델 파일 경로\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    best_loss = checkpoint.get('test_loss', 563.41) # test_loss가 있으면 가져오고, 없으면 563.41 사용\n",
    "    print(f\"✅ Loss {best_loss:.4f}의 모델 가중치 로드 성공.\")\n",
    "    \n",
    "    # 모델 객체에 Loss 값을 저장하여 시각화에 사용\n",
    "    model.current_loss = best_loss \n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠️ 경고: 체크포인트 파일 '{CHECKPOINT_PATH}'을 찾을 수 없습니다. 초기화된 모델로 진행합니다.\")\n",
    "    best_loss = 780.0 # 초기 Loss 값으로 설정\n",
    "except Exception as e:\n",
    "    print(f\"❌ 가중치 로드 중 알 수 없는 오류 발생: {e}. 초기화된 모델로 진행합니다.\")\n",
    "    best_loss = 780.0\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. 이미지 생성 및 시각화 함수 정의\n",
    "# ----------------------------------------------------\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# (CNF 및 ODEFunc 클래스는 이전에 정의되어 있어야 합니다.)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. 이미지 생성 및 시각화 함수 정의 (Logit Transform 복원)\n",
    "# ----------------------------------------------------\n",
    "def generate_and_visualize(model, num_images, input_dim, device):\n",
    "    \n",
    "    model.eval() # 모델을 평가 모드로 설정\n",
    "\n",
    "    # 1. Latent 벡터 생성 (z0 ~ N(0, I))\n",
    "    z0 = torch.randn(num_images, input_dim).to(device).float() \n",
    "    z0.requires_grad_(True) # Trace Estimator 작동을 위해 필요\n",
    "    # 2. logpz_0를 초기화 (Trace 항)\n",
    "    zero_logpz = torch.zeros(z0.shape[0], 1).to(device).float() \n",
    "    \n",
    "    # 3. forward pass 실행: x_gen은 정규화된 [-1, 1] 범위에 있음\n",
    "    input_tuple = (z0, zero_logpz)\n",
    "    x_gen, _ = model.forward(*input_tuple)\n",
    "    x_denorm = torch.sigmoid(x_gen)  # logit 역변환\n",
    "    x_denorm_clipped = torch.clamp(x_denorm, min=0.0, max=1.0)\n",
    "\n",
    "\n",
    "    # 4. 이미지 형태로 복원 (바로 위에서 자른 변수 사용)\n",
    "    x_images = x_denorm_clipped.detach().view(num_images, 28, 28).cpu().numpy()\n",
    "    \n",
    "    # 5. 시각화 및 파일 저장\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n",
    "    \n",
    "    # Loss 값 표시 (로드된 Loss 사용)\n",
    "    try:\n",
    "        loss_display = f\"Loss: {model.current_loss:.2f}\"\n",
    "    except AttributeError:\n",
    "        # 모델에 current_loss가 없을 경우의 대체 값 사용 (새로운 학습 시)\n",
    "        loss_display = \"Loss: N/A (New Training)\"\n",
    "        \n",
    "    plt.suptitle(f\"FFJORD Generated Images ({loss_display})\", fontsize=14)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            # vmin/vmax를 0과 1로 설정하여 올바른 흑백 명암비로 표시\n",
    "            ax.imshow(x_images[i], cmap='gray', vmin=0, vmax=1)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # 🟢 이미지 파일로 저장\n",
    "    output_filename = \"28ffjord_generated_images_no_logit_fix2_.png\"\n",
    "    plt.savefig(output_filename, dpi=300) \n",
    "    plt.close(fig)\n",
    "    print(f\"\\n✅ 이미지 생성이 완료되어 '{output_filename}'으로 저장되었습니다.\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. 함수 호출 예시 (메인 스크립트 마지막에 추가)\n",
    "# ----------------------------------------------------\n",
    "generate_and_visualize(model, NUM_IMAGES_TO_GENERATE, INPUT_DIM, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
